# ğŸ¯ AI Timeout Solution - Implementation Summary

## ğŸš¨ Problem

**Agentic AI requests were timing out at 10 seconds** (Vercel free tier limit), but these requests typically take 15-30+ seconds because they:
1. Build user context from database
2. Call OpenAI API (first time)
3. Execute training plan modifications
4. Call OpenAI API again (to confirm changes)

## âœ… Solution

**Moved agentic AI to Supabase Edge Functions** which have:
- âœ… **No practical timeout** (up to 150 seconds vs 10 seconds)
- âœ… **Free tier friendly**: 500K invocations/month, 2M execution seconds/month
- âœ… **Better for long operations**: Built on Deno, modern and secure
- âœ… **Job tracking**: All requests logged in database for debugging

## ğŸ—ï¸ Architecture

### Before (All on Vercel)
```
User Request â†’ Vercel API Route â†’ OpenAI â†’ Timeout! âŒ
                (10s limit)
```

### After (Hybrid Approach)
```
Regular Chat (< 10s)
User Request â†’ Vercel API Route â†’ OpenAI â†’ Streaming Response âœ…
                (Fast, streaming works great)

Agentic AI (> 10s)
User Request â†’ Supabase Edge Function â†’ OpenAI â†’ Success! âœ…
                (No timeout, up to 150s)
```

## ğŸ“ What Was Created

### 1. Database Schema
**File**: `supabase-ai-jobs-schema.sql`
- Tracks all AI jobs (pending, processing, completed, failed)
- Stores request/response data
- Records execution time for monitoring
- Enables debugging and analytics

### 2. Edge Functions
**Directory**: `supabase/functions/`

#### `ai-chat-agentic/index.ts`
- Handles agentic AI requests with function calling
- No timeout constraints
- Full error handling and job tracking
- Calls training plan modification APIs

#### `build-user-context/index.ts`
- Helper function to build AI context
- Fetches user profile, runs, training plan, memories
- Formats context for AI system message

#### `_shared/training-plan-tools.ts`
- Shared tool definitions for AI function calling
- Used by both Edge Functions and API routes

### 3. Frontend Updates
**File**: `components/dashboard/AIChat.tsx`
- Detects agentic mode
- Routes to Supabase Edge Function for agentic requests
- Shows processing indicator for long operations
- Handles both streaming (Vercel) and JSON (Supabase) responses

### 4. Configuration
**Files**:
- `supabase/config.toml` - Supabase project configuration
- `package.json` - Added helpful npm scripts
- `deploy-edge-functions.sh` - Automated deployment script

### 5. Documentation
**Files**:
- `SUPABASE-EDGE-FUNCTIONS-SETUP.md` - Complete setup guide
- `supabase/functions/README.md` - Developer reference
- `AI-TIMEOUT-SOLUTION.md` - This file!

## ğŸš€ Quick Start

### Option 1: Automated Script
```bash
cd cadence-app
./deploy-edge-functions.sh
```

### Option 2: Manual Steps
```bash
# 1. Install Supabase CLI
npm install -g supabase

# 2. Login and link project
supabase login
supabase link --project-ref YOUR_PROJECT_REF

# 3. Apply database schema
# Go to Supabase Dashboard â†’ SQL Editor
# Run: supabase-ai-jobs-schema.sql

# 4. Set secrets
supabase secrets set OPENAI_API_KEY=your_key_here

# 5. Deploy functions
npm run supabase:deploy

# 6. Test!
# Enable Agentic Mode in AI Chat
# Try: "Move all tempo runs to Thursday"
```

## ğŸ“Š Monitoring

### View Function Logs
```bash
npm run supabase:logs
```

### Check Job History
Query the `ai_jobs` table in Supabase:
```sql
SELECT * FROM ai_jobs 
WHERE user_id = 'your_user_id' 
ORDER BY created_at DESC 
LIMIT 10;
```

### Monitor Usage
- Supabase Dashboard â†’ Edge Functions
- View invocations, execution time, errors
- Track costs (should stay in free tier)

## ğŸ¯ Benefits

### Performance
- âœ… No more timeouts on agentic requests
- âœ… Can handle complex multi-step operations
- âœ… Streaming still works for regular chat

### Cost
- âœ… Stays within free tier limits
- âœ… 500K invocations/month (vs 100K on Vercel)
- âœ… 2M execution seconds/month

### Developer Experience
- âœ… Better error handling and logging
- âœ… Job tracking for debugging
- âœ… Easy to monitor and optimize
- âœ… Separate concerns (fast vs slow operations)

### User Experience
- âœ… No failed requests due to timeout
- âœ… Processing indicator shows progress
- âœ… Reliable agentic AI modifications
- âœ… Fast streaming for regular chat

## ğŸ”„ How It Works

### Regular Chat Flow (Advice Mode)
1. User sends message
2. Frontend calls `/api/ai/chat` (Vercel)
3. Vercel streams response from OpenAI
4. User sees response in real-time
5. **Total time**: 2-5 seconds âœ…

### Agentic Chat Flow (Agentic Mode)
1. User sends message
2. Frontend shows "Processing..." indicator
3. Frontend calls Supabase Edge Function
4. Edge Function:
   - Creates job record (status: processing)
   - Builds user context
   - Calls OpenAI with function calling
   - Executes training plan modifications
   - Calls OpenAI again to confirm
   - Updates job record (status: completed)
5. Frontend receives response
6. User sees result with modifications badge
7. **Total time**: 15-30 seconds âœ… (no timeout!)

## ğŸ†š Comparison

| Feature | Vercel Functions | Supabase Edge Functions |
|---------|-----------------|------------------------|
| **Timeout** | 10s (free tier) | 150s max |
| **Invocations** | 100K/month | 500K/month |
| **Execution Time** | Limited | 2M seconds/month |
| **Streaming** | âœ… Excellent | âœ… Supported |
| **Best For** | Quick responses | Long operations |
| **Our Use** | Regular chat | Agentic AI |

## ğŸ‰ Result

**Problem Solved!** 
- Agentic AI requests no longer timeout
- Users can reliably modify training plans via AI
- System stays within free tier limits
- Better monitoring and debugging capabilities

## ğŸ“š Additional Resources

- [Supabase Edge Functions Docs](https://supabase.com/docs/guides/functions)
- [Deno Manual](https://deno.land/manual)
- [OpenAI Function Calling](https://platform.openai.com/docs/guides/function-calling)

## ğŸ› Troubleshooting

See `SUPABASE-EDGE-FUNCTIONS-SETUP.md` for detailed troubleshooting steps.

Common issues:
- **Function not found**: Run `npm run supabase:deploy`
- **Auth errors**: Check environment variables
- **Still timing out**: Check OpenAI API response time
- **CORS errors**: Verify `corsHeaders` in Edge Function

